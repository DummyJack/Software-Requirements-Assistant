# main.py
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import OpenAI
from pathlib import Path
from datetime import datetime
import openai as openai_pkg  # åªç”¨ä¾†å°å‡ºç‰ˆæœ¬ï¼Œæ–¹ä¾¿é™¤éŒ¯

app = FastAPI()

# å…è¨±å‰ç«¯é€£ç·šï¼ˆä¾‹å¦‚ä½ çš„æœ¬åœ° HTMLï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å¯æ”¹æˆ ["http://localhost:3000"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# === è®€å–å¤–éƒ¨ system prompt ===
SYSTEM_PROMPT_PATH = Path("system_prompt.txt")
if not SYSTEM_PROMPT_PATH.exists():
    raise FileNotFoundError("âŒ æ‰¾ä¸åˆ° system_prompt.txtï¼Œè«‹ç¢ºèªæª”æ¡ˆå­˜åœ¨æ–¼åŒç›®éŒ„ä¸‹ã€‚")

SYSTEM_PROMPT = SYSTEM_PROMPT_PATH.read_text(encoding="utf-8")


# === å‰ç«¯å‚³å…¥è³‡æ–™æ ¼å¼ ===
class PromptRequest(BaseModel):
    api_key: str
    prompt: str


class TestKeyRequest(BaseModel):
    api_key: str


def generate_with_compat(client: OpenAI, system_prompt: str, user_prompt: str) -> str:
    """
    SDK ç›¸å®¹å±¤ï¼š
    - è‹¥æ”¯æ´ Responses API (>=1.42)ï¼Œèµ° client.responses.create(...)
    - å¦å‰‡é€€å›èˆŠçš„ Chat Completions API
    """
    # æ–°ç‰ˆ (>=1.42) æœƒæœ‰ responses ä»‹é¢
    if hasattr(client, "responses"):
        resp = client.responses.create(
            # ä½ åŸæœ¬ç”¨ gpt-4.1ï¼›é€™è£¡æ²¿ç”¨ã€‚å¦‚æœç„¡æ¬Šé™ï¼Œå¯æ”¹ç‚º "gpt-4o-mini" / "gpt-5-mini"
            model="gpt-4.1",
            input=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
        )
        # æ–° SDK æœ€ç°¡å–®çš„æ–‡å­—è¼¸å‡º
        txt = getattr(resp, "output_text", None)
        if txt:
            return txt.strip()
        # é€€è€Œæ±‚å…¶æ¬¡ï¼ˆä¸åŒå°ç‰ˆåºåˆ—åŒ–ç•¥æœ‰å·®ç•°ï¼‰
        return resp.output[0].content[0].text.strip()

    # èˆŠç‰ˆ (1.0 ~ 1.41) ä½¿ç”¨ chat.completions
    comp = client.chat.completions.create(
        # è‹¥ "gpt-4.1" ä¸å¯ç”¨ï¼Œæ”¹æˆ "gpt-4o-mini" æˆ–ä½ æœ‰æ¬Šé™çš„æ¨¡å‹
        model="gpt-4.1",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
    )
    return comp.choices[0].message.content.strip()


@app.post("/generate")
def generate_text(req: PromptRequest):
    client = OpenAI(api_key=req.api_key)
    try:
        # === é¡¯ç¤ºè¼¸å…¥ ===
        print("\n" + "=" * 80)
        print(f"ğŸ•’ æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("[OpenAI SDK] version:", getattr(openai_pkg, "__version__", "unknown"))
        print("ğŸŸ¢ ä½¿ç”¨è€…è¼¸å…¥çš„ promptï¼š")
        print(req.prompt)
        print("-" * 80)

        # === å‘¼å« OpenAIï¼ˆç›¸å®¹å±¤ï¼‰===
        output = generate_with_compat(client, SYSTEM_PROMPT, req.prompt)

        # === é¡¯ç¤ºè¼¸å‡º ===
        print("ğŸŸ£ æ¨¡å‹å›æ‡‰ï¼š")
        print(output)
        print("=" * 80 + "\n")

        return {"result": output}

    except Exception as e:
        print("âŒ [ERROR]", e)
        raise HTTPException(status_code=400, detail=str(e))


@app.post("/test-openai")
def test_openai(req: TestKeyRequest):
    """
    è¼•é‡é©—è­‰ OpenAI API Keyï¼š
    - æˆåŠŸï¼šå›å‚³ {"ok": True}
    - å¤±æ•—ï¼šHTTP 400 with detail
    ä½¿ç”¨ models.list() åš metadata æŸ¥è©¢ï¼Œä¸æœƒæ¶ˆè€— tokensã€‚
    """
    try:
        client = OpenAI(api_key=req.api_key)
        # åˆ—å‡ºæ¨¡å‹åƒ…ç‚ºé©—è­‰é‡‘é‘°æœ‰æ•ˆæ€§ï¼ˆä¸è¨ˆè²»ï¼‰
        _ = client.models.list()
        return {"ok": True, "message": "OpenAI key is valid."}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))
